{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P07_03_ML_studio_designer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NoIPCvoi3A5"
      },
      "source": [
        "![air-paradis](https://drive.google.com/uc?id=1T26mpOAUvJP700W4m8bjfYCLmDYVcyJL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXPqk-gZi6rv"
      },
      "source": [
        "# <font color=red><center>**AIR PARADIS**</center></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cXAbfKgi79d"
      },
      "source": [
        "**Air Paradis** is an airline company that wants to use AI (*Artificial Intelligence*) to **detect Bad Buzz associated with its brand** in online public tweets.\n",
        "\n",
        "**As AI engineer for Marketing Intelligence Consulting**, we will dive into **NLP** (*Natural Language Processing*) techniques to serve Air Paradis' purpose.\n",
        "\n",
        "Indeed, NLP allows a machine to **understand and process human language**. It will help us to solve this **text classification goal** and **detect sentiment** (positive or negative) from these tweets.\n",
        "\n",
        "We will deploy our best **DETECT SENTIMENT solution** through <font color=salmon>**Microsoft Azure Machine Learning plateform**</font> (***MS Azure ML***).\n",
        "\n",
        "<br>\n",
        "\n",
        "Therefore, we will structure the project as follows:\n",
        "\n",
        "<br>\n",
        "\n",
        "| **Services / Tools** | **Objective** | **Available notebook** |\n",
        "| :-- | :-- | :-- |\n",
        "| **Google Colab and Python libraries** | Build quality of data by pre-processing the tweets text | Notebook N°1 |\n",
        "| **Google Colab / MS Azure Cognitive Services API** | Use Text Analytics > Sentiment API | Notebook N°2 |\n",
        "| **Python Script / MS Azure ML Studio > Designer** | Use \"Drag-and-Drop\" pipeline with no code in Azure ML Studio| **<font color=green>Notebook N°3</font>** |\n",
        "| **Tensorflow-Keras / Google Colab PRO with GPU/TPU** | Train and evaluate advanced models | Notebook N°4 |\n",
        "| **MS Azure ML Cloud > Models** | Deploy the best solution in MS Azure WebService | Notebook N°5 |\n",
        "\n",
        "<br>\n",
        "\n",
        "This notebook is dedicated to 3rd task : **test Azure Machine Learning Studio Designer to build and train a logistic regression model as Sentiment classification**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlHJhoP2jaX6"
      },
      "source": [
        "# <font color=brown><center>**NOTEBOOK 3<br>AZURE MACHINE LEARNING STUDIO<br>LOGISTIC REGRESSION PIPELINE**</center></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeFrdABRkU9f"
      },
      "source": [
        "![aml-studio](https://drive.google.com/uc?id=1H-cir-dzjvvU8ggTfmVcILDtLmAD_mfL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pYNT_Ak8r6U"
      },
      "source": [
        "# <font color=salmon>PART 1 - AZURE MACHINE LEARNING STUDIO</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D41GDNGK8x-b"
      },
      "source": [
        "## <font color=green>P1.1 - Understand Azure ML Studio</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsEZWYC61q1E"
      },
      "source": [
        "**Azure Machine Learning** is a cloud-based environment that can be used to **train, deploy, automate, manage, and track ML models**.\n",
        "\n",
        "**Azure Machine Learning Studio** is a web portal in Azure Machine Learning for **low-code and no-code options** for model training, deployment, and asset management:\n",
        "- **Notebooks**, directly integrated to write and run our own code in managed Jupyter Notebook servers;\n",
        "- **Designer**, with Drag-and-drop interface to train and deploy machine learning models as *pipeline*, with low or no-code;\n",
        "- **Experiment**, to diagnose errors and warnings, or track performance metrics of experiments scaled with compute target;\n",
        "- **Compute**, to manage a wide and customizable range of compute ressources.\n",
        "\n",
        "The documentation about Azure ML Studio can be found [here](https://ml.azure.com/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnvIh_Ve8ZMx"
      },
      "source": [
        "![designer](https://drive.google.com/uc?id=1ZCh32XNfGvUIfqR8DNZNdhQCsODuWda7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUQTryr_rQNI"
      },
      "source": [
        "An **AML workplace** is necessary to interact with AML Studio.\n",
        "\n",
        "This workplace is the centralized place which contains all the components that allows us to create, use and register any of Azure Machine Learning resources.\n",
        "\n",
        "The documentation about the workspace can be found [here](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcxYL9lM_k2A"
      },
      "source": [
        "## <font color=green>P1.2 - Understand Azure ML Designer</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf7O6wRgNOsY"
      },
      "source": [
        "As said previously, the **Designer** is a **drag-and-drop** tool used to create machine learning models with no code or low code.\n",
        "\n",
        "In the Designer interface, Azure Machine Learning Studio gives 2 options:\n",
        "- **Create from scratch a new pipeline**;\n",
        "- **Clone one of the available sample pipelines** and adapt it to our need.\n",
        "\n",
        "We have chosen the 2nd option: \n",
        "- Clone the **Text Classification - Wikipedia SP 500 Dataset** sample;\n",
        "- Adapt the easy-to-use prebuilt modules to our needs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JELe6Ve6AItE"
      },
      "source": [
        "![create](https://drive.google.com/uc?id=1i813a14CVo9pkmesFV7a--SM3M-Dekll)![sample](https://drive.google.com/uc?id=16_8cWEXomO6qeT_9m8_6UF0efShv9WQq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLv__zXBTdss"
      },
      "source": [
        "## <font color=green>P1.3 - Understand pipeline steps and modules</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmVLh2-4V8r0"
      },
      "source": [
        "The pipeline is a **series of steps called \"modules\", connected to each other in order to build a complete workflow of a machine learning task**.\n",
        "\n",
        "A **module** is an algorithm that can be performed on the data, such as:\n",
        "- **Data preparation**: dataset importation, sampling, data cleaning;\n",
        "- **Data transformation**: hashing and n-grams features from text;\n",
        "- **Data split in subsets**: train and test sets;\n",
        "- **Model selection**: regression, classification;\n",
        "- **Training configuration**: especially, compute resources;\n",
        "- **Progress monitoring**: errors and warning diagnosis, performance tracking,..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCt5ESvs89Hb"
      },
      "source": [
        "# <font color=salmon>PART 2 - WORK WITH CLONED PIPELINE</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KvxBuWssaLg"
      },
      "source": [
        "## <font color=green>P2.1 - Use Sample dataframe</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr0cqJ8YxbOd"
      },
      "source": [
        "First we need to use our sample dataframe to replace the \"Wikipedia SP 500 Dataset\" in the pipeline.\n",
        "\n",
        "As seen in our first notebook, the text that has the best performance is **cleaned_tweet**, which have been pre-processed but have kept stopwords, and are not lemmatized.\n",
        "\n",
        "We will use to keep all our models **comparable**, with roughly same variables to appy, except sample size and some little variations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4zPkstbTv_l",
        "outputId": "ea9c447d-67f1-43e5-f566-dbc86c5fa9fe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyqRIDbD7tF0"
      },
      "source": [
        "Let's get to AML Studio to load it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNprOgDaUOlE"
      },
      "source": [
        "## <font color=green>P2.2 - Clone existing pipeline</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFpHaU-JA5Zd"
      },
      "source": [
        "When we click on **Designer** in the left menu, we know have a copy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2gaM3RGXAf2"
      },
      "source": [
        "![amls-clone](https://drive.google.com/uc?id=1vS54I9EwnjorLi4srugtADTc077rCDtw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M43BBHYw8mDb"
      },
      "source": [
        "## <font color=green>P2.3 - Register our sample dataset</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8wLkN9f8-Vb"
      },
      "source": [
        "Then, we go to AML Studio again and choose **Datasets** in the left menu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U24aKLl8z9s"
      },
      "source": [
        "![dataset](https://drive.google.com/uc?id=1TmynispJorTdtqMnQmnvqvSfRj8nZZ7T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfYKm2O4CGdQ"
      },
      "source": [
        "## <font color=green>P2.4 - Adapt cloned pipeline</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYIzCcNlDymz"
      },
      "source": [
        "### <font color=blue>P2.4.1 - 1st step : change the dataset</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYUp-_OuEAL9"
      },
      "source": [
        "We just need to click on the module of the old dataset (Wikipedia), delete it and drag-and-drop the new dataset.\n",
        "\n",
        "Eventually, we can change some parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqYh55chDy_Z"
      },
      "source": [
        "![change](https://drive.google.com/uc?id=1LLIAjUhMlyRWh8ZDu01U485xpJse-f6j)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzPyyXuREvTa"
      },
      "source": [
        "### <font color=blue>P2.4.2 - Following steps : adjust the parameters of other modules</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm6_h0ijE3g-"
      },
      "source": [
        "The following actions have been done:\n",
        "- **Preprocess Text** has been removed as we do want the model to predict on our cleaned tweet;\n",
        "- **Split Data** has been re-ajusted to 0.8 Train set and 0.2 Test set, add a Random seed (42), keep the data with *stratified split*;\n",
        "- We have changed the model from *Multiclass Logistic Regression* to **Two-Class Logistic Regression** with random seed = 42, as classification algorithm.\n",
        "\n",
        "In the cloned pipeline, 2 models of Text Data transformation are used:\n",
        "- Feature Hashing;\n",
        "- Extract N-Gram Features from Text.\n",
        "\n",
        "The unique parameter we have changed for both is *Target column* to match our cleaned tweet.\n",
        "\n",
        "The rest was kept inchanged : **Train Model, Score Model, Evaluate Model**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bnhH-q_LsMB"
      },
      "source": [
        "![pipeline](https://drive.google.com/uc?id=1OZVcDQBxCdJrl1aPF7vngLXLdkXADLeJ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp3rBF6IL3m2"
      },
      "source": [
        "## <font color=green>P2.5 - Set up compute target</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaW-gloqMFDc"
      },
      "source": [
        "Here again, we have 2 choices to create a compute target:\n",
        "- Create one with the predefined configuration;\n",
        "- Create a compute cluster ==> this is the option we took."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqwQPHqLRiby"
      },
      "source": [
        "## <font color=green>P2.5 - Set up pipeline run and submit</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cdc8YJQodv4"
      },
      "source": [
        "We just have to create the experiment by giving a name."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxjknAOh8TNw"
      },
      "source": [
        "<font color=red>And we wait BUT we encountered a lot of hiccups and we had to run 14 submissions before we got a result!</font>.\n",
        "\n",
        "This is not what I would qualify of an **\"easy drag-and-drop\"** tool, but it's a personal opinion.\n",
        "\n",
        "Besides, it requires a minimum of understanding of how each algorithm is working - in terms of input and output requirements or parameters, to be able to debug when the runs of each module fail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOt9L9jH8wsb"
      },
      "source": [
        "## <font color=green>P2.6 - Evaluate the result</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_CbCbBQ5ASd"
      },
      "source": [
        "\n",
        "As we have split our 1600 data to 0.8% Train and 0.2% Test, the evaluation was made on 320 data rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8FuefgN5Z0z"
      },
      "source": [
        "### <font color=blue>P2.6.1 - Evaluate feature hashing (left port)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaBl8rb156WU"
      },
      "source": [
        "**Feature Hashing** module transforms a stream of English text into a set of integer features.\n",
        "\n",
        "It operates on the exact **strings** provided as input and does not perform any linguistic analysis or preprocessing.\n",
        "\n",
        "Internally, the Feature Hashing module creates a dictionary of n-grams, the size of the n-grams can be controled by using the N-grams property.\n",
        "\n",
        "After the dictionary is built, the Feature Hashing module converts the dictionary terms into hash values. It then computes whether a feature was used in each case. For each row of text data, the module outputs a set of columns, one column for each hashed feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMs-MkaI-kH1"
      },
      "source": [
        "#### **Visualize transformed dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xZi4Ub5-5u4"
      },
      "source": [
        "![dataset](https://drive.google.com/uc?id=143xei5Kr3k9gB9u-jHbJPWe14p0M0b-R)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SseuyUTi-qHF"
      },
      "source": [
        "#### **Visualize metrics and confusion matrix**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOOnxMJWyGgY"
      },
      "source": [
        "***Observations***:\n",
        "- First, we note that the confusion matrix is not plotted as usual, that means, it is structured differently: the actual values are in the top (abscissa) and the predicted values are in the left (ordinate); besides, positive value (1) is given first; in the figure, the True Positives are in the top-left box, and the True Negatives are in the bottom-right box."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux5OWgT-BR9l"
      },
      "source": [
        "![left](https://drive.google.com/uc?id=18Dor4k9xMv47L7BjJQmYPLKil6YjKfX3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iF5CiSW97Iu"
      },
      "source": [
        "<font color=red>**Note that the model has its best accuracy (0.634) at 0.5 classification threshold.**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mitXfvV7DIv"
      },
      "source": [
        "### <font color=blue>P2.6.2 - Evaluate n-gram extraction features from text (right port)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31zqgOwwACnd"
      },
      "source": [
        "The **Extract N-Gram Features from Text** module *featurizes* unstructured text data. \n",
        "\n",
        "It creates a new list of n-grams from dictionary provided by the processed column of raw text: for example, if the N-Gram size is 2, unigrams and bigrams will be created.\n",
        "\n",
        "The <code>**weighting function**</code> was set to **TF-IDF Weight**, that means, that, *term frequency/inverse document frequency (TF/IDF) score* is assigned to the extracted n-grams. The value for each n-gram is its TF score multiplied by its IDF score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_3NlTRh-0T7"
      },
      "source": [
        "#### **Visualize transformed dataset and vocabulary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN8aBrbU_jYo"
      },
      "source": [
        "![dataset](https://drive.google.com/uc?id=1ksxl6vmNd6JPqBSkPZA98fM37YRDym-U) ![vocab](https://drive.google.com/uc?id=1LNmFLhPjRndDG6kGv6HbzvU5egzfBqhW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ECjgo1T-0T8"
      },
      "source": [
        "#### **Visualize metrics and confusion matrix**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6DmhhMJBjZr"
      },
      "source": [
        "![right](https://drive.google.com/uc?id=1Z6SduZEsmH898PTW2dq5L0K2_qQ-GnRa)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xYnUdmZ-MNZ"
      },
      "source": [
        "<font color=red>**Note that the model has its best accuracy (0.706) at 0.5 classification threshold.**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYyL0bbaF2KE"
      },
      "source": [
        "The result can be summarized as below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "qXpWmonWUcdC",
        "outputId": "a394d56c-cd00-4b8b-9bd6-30c820cc048c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create empty list\n",
        "scores_model = []\n",
        "\n",
        "# Append scores/results\n",
        "scores_model.append({'Model': 'Studio - Feat. hashing',\n",
        "                     'Predict_time':'{:0.1f}'.format(60+21.45),\n",
        "                     'AUC_Score':'{:0.3f}%'.format(70.2),\n",
        "                     'Accuracy':'{:0.3f}%'.format(63.4)})\n",
        "\n",
        "# Save in DF\n",
        "model_results = pd.DataFrame.from_records(scores_model)\n",
        "\n",
        "# Append scores/results\n",
        "model_results = model_results.append({'Model': 'Studio - N-grams extraction',\n",
        "                                      'Predict_time':'{:0.1f}'.format(60+43.43),\n",
        "                                      'AUC_Score':'{:0.3f}%'.format(78.4),\n",
        "                                      'Accuracy':'{:0.3f}%'.format(70.6)},\n",
        "                                     ignore_index=True)\n",
        "\n",
        "model_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Predict_time</th>\n",
              "      <th>AUC_Score</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Studio - Feat. hashing</td>\n",
              "      <td>81.5</td>\n",
              "      <td>70.200%</td>\n",
              "      <td>63.400%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Studio - N-grams extraction</td>\n",
              "      <td>103.4</td>\n",
              "      <td>78.400%</td>\n",
              "      <td>70.600%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Model Predict_time AUC_Score Accuracy\n",
              "0       Studio - Feat. hashing         81.5   70.200%  63.400%\n",
              "1  Studio - N-grams extraction        103.4   78.400%  70.600%"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BluU-6vOL9vf"
      },
      "source": [
        "from pathlib import Path\n",
        "src_folder = Path('/content/drive/MyDrive/OC_IA/P07')\n",
        "\n",
        "# Save to CSV file\n",
        "model_results.to_csv(src_folder / 'p7_03_model_results.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKNy4yEIpTwU"
      },
      "source": [
        "## <font color=green>P2.7 - Get experiment link for presentation</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HieQUlXsTMir"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "# Install azure ml SDK\n",
        "!pip install azureml-core\n",
        "# !pip install azureml-pipeline\n",
        "# !pip install azureml-pipeline-core\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxxtdUlJTRzE",
        "outputId": "0060a733-ff77-4e72-fe9b-8f3d345e4a3a"
      },
      "source": [
        "import azureml.core\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Azure ML SDK Version:  1.36.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDJZO3R7VjK6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16f314a3-65eb-491a-f48f-1c48af445d87"
      },
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "# Connect to workspace\n",
        "ws = Workspace.from_config('/content/drive/MyDrive/OC_IA/P07/p7_03_ws_config.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing interactive authentication. Please follow the instructions on the terminal.\n",
            "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code RM4CT33UY to authenticate.\n",
            "You have logged in. Now let us find all the subscriptions to which you have access...\n",
            "Interactive authentication successfully completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BZrk-EtV0Dn",
        "outputId": "571f7b7e-46c6-410f-fe98-2ef335f75438"
      },
      "source": [
        "from azureml.core.experiment import Experiment\n",
        "\n",
        "# Get a list of all Experiment object in a Workspace\n",
        "list_experiments = Experiment.list(ws)\n",
        "list_experiments"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Experiment(Name: OCIA_P07,\n",
              " Workspace: OC_IA_Tyson)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "WA4TQGf8XYkt",
        "outputId": "4e04467b-6069-4136-8b16-fb029b3975aa"
      },
      "source": [
        "# Retrieved from Azure Machine Learning web UI\n",
        "run_id = '4ce36137-4bc1-48d6-8619-8bb9a7a30dc0'\n",
        "exp = ws.experiments['OCIA_P07']\n",
        "run = next(run for run in exp.get_runs() if run.id == run_id)\n",
        "run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>OCIA_P07</td><td>4ce36137-4bc1-48d6-8619-8bb9a7a30dc0</td><td>azureml.PipelineRun</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/4ce36137-4bc1-48d6-8619-8bb9a7a30dc0?wsid=/subscriptions/54d05a91-2c96-4ea6-b7ed-a07824575e62/resourcegroups/OC_IA/workspaces/OC_IA_Tyson&amp;tid=22b02e1d-09ac-4038-84b3-8b7577a3aa43\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
            ],
            "text/plain": [
              "Run(Experiment: OCIA_P07,\n",
              "Id: 4ce36137-4bc1-48d6-8619-8bb9a7a30dc0,\n",
              "Type: azureml.PipelineRun,\n",
              "Status: Completed)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqfpmeS13n48"
      },
      "source": [
        "# <font color=salmon>CONCLUSION</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag94MlzL3q__"
      },
      "source": [
        "From our point of view, this tool does not keep its promises : it is supposed to be straightforward, BUT IT IS NOT AT ALL.\n",
        "\n",
        "We have to admit that Microsoft lacks in pedagogy and it has trouble presenting his tutorials in a sequential manner, keeping in mind the context in which the tool is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "irgkSQF8q7Nh",
        "outputId": "44a730a8-4e3d-4b86-93a3-10c4b357345d"
      },
      "source": [
        "# Load result Sentiment API\n",
        "results1 = pd.read_csv(src_folder / 'p7_02_model_results.csv')\n",
        "# results1.reset_index(drop=True, inplace=True)\n",
        "results1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Predict_time</th>\n",
              "      <th>AUC_Score</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Original tweets</td>\n",
              "      <td>186.1</td>\n",
              "      <td>74.349%</td>\n",
              "      <td>74.335%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cleaned tweets</td>\n",
              "      <td>192.2</td>\n",
              "      <td>75.989%</td>\n",
              "      <td>75.949%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lemmatized tweets</td>\n",
              "      <td>184.0</td>\n",
              "      <td>75.380%</td>\n",
              "      <td>75.319%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Model  Predict_time AUC_Score Accuracy\n",
              "0    Original tweets         186.1   74.349%  74.335%\n",
              "1     Cleaned tweets         192.2   75.989%  75.949%\n",
              "2  Lemmatized tweets         184.0   75.380%  75.319%"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRo_FGt2rLn1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "960dd9d9-9875-4eae-f879-b2b00babe3da"
      },
      "source": [
        "# Load result ML Studio\n",
        "results2 = pd.read_csv(src_folder / 'p7_03_model_results.csv')\n",
        "# results2.reset_index(drop=True, inplace=True)\n",
        "results2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Predict_time</th>\n",
              "      <th>AUC_Score</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Studio - Feat. hashing</td>\n",
              "      <td>81.5</td>\n",
              "      <td>70.200%</td>\n",
              "      <td>63.400%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Studio - N-grams extraction</td>\n",
              "      <td>103.4</td>\n",
              "      <td>78.400%</td>\n",
              "      <td>70.600%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Model  Predict_time AUC_Score Accuracy\n",
              "0       Studio - Feat. hashing          81.5   70.200%  63.400%\n",
              "1  Studio - N-grams extraction         103.4   78.400%  70.600%"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}